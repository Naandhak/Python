{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5545879-970f-44a7-b2a8-fee8a46857c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 1 - Please download dataset or generate it using the attached script dataset_generator.py\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import random\n",
    "import string\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "letters = string.ascii_lowercase\n",
    "letters_upper = string.ascii_uppercase\n",
    "for _i in range(0, 10):\n",
    "    letters += letters\n",
    "\n",
    "for _i in range(0, 10):\n",
    "    letters += letters_upper\n",
    "\n",
    "\n",
    "def random_string(stringLength=10):\n",
    "    \"\"\"Generate a random string of fixed length \"\"\"\n",
    "    return ''.join(random.sample(letters, stringLength))\n",
    "\n",
    "\n",
    "print(\"Products between {} and {}\".format(1, 100000))\n",
    "product_ids = [x for x in range(1, 100000)]\n",
    "dates = ['2020-07-01', '2020-07-02', '2020-07-03', '2020-07-04', '2020-07-05', '2020-07-06', '2020-07-07', '2020-07-08', '2020-07-09', '2020-07-10']\n",
    "seller_ids = [x for x in range(1, 10)]\n",
    "\n",
    "\n",
    "#   Generate products\n",
    "products = [[0, \"product_0\", 22]]\n",
    "for p in tqdm(product_ids):\n",
    "    products.append([p, \"product_{}\".format(p), random.randint(1, 150)])\n",
    "#   Save dataframe\n",
    "df = pd.DataFrame(products)\n",
    "df.columns = [\"product_id\", \"product_name\", \"price\"]\n",
    "df.to_csv(\"products.csv\", index=False)\n",
    "del df\n",
    "del products\n",
    "\n",
    "#   Generate sellers\n",
    "sellers = [[0, \"seller_0\", 100000]]\n",
    "for s in tqdm(seller_ids):\n",
    "    sellers.append([s, \"seller_{}\".format(s), random.randint(0, 100000)])\n",
    "#   Save dataframe\n",
    "df = pd.DataFrame(sellers)\n",
    "df.columns = [\"seller_id\", \"seller_name\", \"daily_target\"]\n",
    "df.to_csv(\"sellers.csv\", index=False)\n",
    "\n",
    "#   Generate sales\n",
    "total_rows = 100000\n",
    "prod_zero = int(total_rows * 0.95)\n",
    "prod_others = total_rows - prod_zero + 1\n",
    "df_array = [[\"order_id\", \"product_id\", \"seller_id\", \"date\", \"num_pieces_sold\", \"bill_raw_text\"]]\n",
    "with open('sales.csv', 'w', newline='') as f:\n",
    "    csvwriter = csv.writer(f)\n",
    "    csvwriter.writerows(df_array)\n",
    "\n",
    "order_id = 0\n",
    "for i in tqdm(range(0, 40)):\n",
    "    df_array = []\n",
    "\n",
    "    for i in range(0, prod_zero):\n",
    "        order_id += 1\n",
    "        df_array.append([order_id, 0, 0, random.choice(dates), random.randint(1, 100), random_string(500)])\n",
    "\n",
    "    with open('sales.csv', 'a', newline='') as f:\n",
    "        csvwriter = csv.writer(f)\n",
    "        csvwriter.writerows(df_array)\n",
    "\n",
    "    df_array = []\n",
    "    for i in range(0, prod_others):\n",
    "        order_id += 1\n",
    "        df_array.append(\n",
    "            [order_id, r6andom.choice(product_ids), random.choice(seller_ids), random.choice(dates),\n",
    "             random.randint(1, 100), random_string(500)])\n",
    "\n",
    "    with open('sales.csv', 'a', newline='') as f:\n",
    "        csvwriter = csv.writer(f)\n",
    "        csvwriter.writerows(df_array)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277c13a-43f4-4a6a-9c74-da15b03a8322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------TASK 1----------------------------------------------\n",
    "#importing SparkSession class\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc47be65-333f-4113-ba44-83887592d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning config to spark variable\n",
    "spark=SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Python Spark SQL basic example\") \\\n",
    ".config(\"spark.some.config.option\",\"some-value\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c9a3f-31cd-4699-bfea-7dc71597b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating sparkcontext\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca55d1b7-323a-42fa-af0e-0614fd9da50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1. Please upload data from sellers.csv into sellers_rdd variable. Use the textFile method with map function: \n",
    "sellers_rdd=sc.textFile(\"/home/jovyan/work/sellers.csv\").map(lambda x:x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650092e8-b947-4811-9fbc-65c8887f193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3. Save the first element of sellers_rdd into sellers_rdd_header variable\n",
    "sellers_rdd_header=sellers_rdd.top(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f101f09-af2c-491e-90df-2f67ace0b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.4. Filter the sellers_rdd excluding the sellers_rdd_header value, and reassign it to sellers_rdd. \n",
    "sellers_rdd=sellers_rdd.filter(lambda x:x not in sellers_rdd_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a54d28-95e9-4be1-b3fd-2380209d52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellers_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935d1761-76f1-41da-be0f-cfed5c4f4657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\tCreate a DataFrame variable sellers_df_test using toDF() function.\n",
    "sellers_df_test=sellers_rdd.toDF(schema=sellers_rdd_header[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ee637-d37c-48a2-9430-438f94d6d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.\tRun the following code in order to change data types \n",
    "sellers_rdd = sellers_rdd.map(lambda x: (int(x[0]),x[1],int(x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f41c0c5-197a-4e92-9738-aba57ebbd016",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellers_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b86994-8f44-4623-a1ef-57ba158192b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.\tRecreate a DataFrame variable sellers_df using createDataFrame() function. For this task you need to create a schema. \n",
    "#Review the dataset in order to choose correct data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452cba52-86be-48a8-b59a-e2c39f83bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a schema\n",
    "from pyspark.sql.types import *\n",
    "sellers_rdd_head=StructType([StructField('seller_id',IntegerType(),True),\n",
    "StructField('seller_name',StringType(),True),\n",
    "StructField('daily_target',IntegerType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b79acd-a5d7-4e78-8177-12ded09cf49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recreate a DataFrame variable sellers_df using createDataFrame() function.\n",
    "sellers_df=spark.createDataFrame(sellers_rdd,schema=sellers_rdd_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8138e0fc-f2b8-4bee-add4-aba4a8ebfa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6273d186-126f-4c20-bc46-8502d03f0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review the dataset in order to choose correct data types.\n",
    "sellers_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c390a80-d86d-4d59-8708-52cafc0bb7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.\tCreate a Pandas dataframe sellers_df_pd  from Spark dataframe.\n",
    "sellers_df_Pandas=sellers_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7383fc0-5c43-4487-a080-61560d03971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.\tTake first 5 rows of sellers_df\n",
    "sellers_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e669c5c3-365f-419c-a75f-76ac7d4ca97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.\tReturn a schema and dtypes of sellers_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8772e21-01de-4c48-9c3f-5b10ed25cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellers_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f60da-7134-4dea-8736-e33b48236776",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellers_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45487f03-3fad-4680-8d98-e5ced89eb23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.\tUpload data from products.csv to products_df Dataframe variable and sales.csv to sales_df using the spark.read.csv() function.\n",
    "#Please take a look on the header parameter while data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407b5c9-9d3a-4c85-9a5e-65706a4bc9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df=spark.read.csv(\"/home/jovyan/work/products.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21cf6f-9498-4a44-8e35-c79faa1ff67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089196b2-9a6d-42b8-b25c-894c7b623ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df=spark.read.csv(\"/home/jovyan/work/sales.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9995fd5d-f68e-4c6a-88be-4f536c853c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca5c4d-62b2-400b-83ef-1768786f26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.\tShow the summary statistic of products_df\n",
    "products_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5f416-892a-43b2-836c-5edffe0f126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.\tPrint the physical and logical plans of products_df\n",
    "products_df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f42d8d-238a-45a6-bc3c-e227900adece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.\tCount a number of distinct rows of products_df\n",
    "products_df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7133ecf-2e94-4635-abaa-4a09c427f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.\tTransform a dataframe to RDD products_rdd variable using products_df.rdd method and print a number of partitions\n",
    "products_rdd=products_df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887df3c-9940-4307-9436-1f8a192c1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09035e6-0eab-41c9-ba91-846508996ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.\tFilter products_df where price > 100 and save a dataframe to the products_df_more_than_100.csv file. \n",
    "products_csv=products_df.filter(products_df[\"price\"]>100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46194aec-3eb4-434c-b735-5a45532240d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_csv.write.csv(\"/home/jovyan/work/products_df_more_than_100\",mode=\"overwrite\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a5a9e-f297-40db-95bc-5405f8f7b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a7191-46bf-4f58-8f01-46156810e557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d0aee-d6f0-4d01-ab4b-87a3e1279798",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = re.search('[^\\s\\\\]',str(products_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936a67c-6ef3-4e6a-a182-8b495c1264af",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.toJSON().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "aabeff23-64c3-4496-b598-c47ff72ae786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.\tSave products_df to JSON and Parquet files.\n",
    "#8.\tSave products_df to JSON and Parquet files.\n",
    "products_df.write.json(\"/home/jovyan/work/products_df_json\",mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "16186e5c-b215-4420-b505-6ef6fd293bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.\tSave products_df to JSON and Parquet files.\n",
    "products_df.write.parquet(\"/home/jovyan/work/products_df_parquet\",mode=\"overwrite\",partitionBy='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44a582-b189-4e61-9de5-2b1808ff77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.\tUpload the JSON file from the step above to the products_df_from_json Dataframe variable and show the content of it.\n",
    "products_df_from_json=spark.read.json(\"/home/jovyan/work/products_df_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e335eb8-f2cb-41b3-9b2f-781c0c93feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df_from_json.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced24466-3890-4a17-83d9-341f249d1f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
